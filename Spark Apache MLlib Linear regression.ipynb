{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mechanical-french",
   "metadata": {},
   "source": [
    "## TASK: Implementing Machine Learning Model Using Apache Spark MLlib\n",
    "\n",
    "Implementation of Linear regression: Predicting Person's Weight Using Gender and Height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-pillow",
   "metadata": {},
   "source": [
    "Documentation: https://spark.apache.org/mllib/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-robinson",
   "metadata": {},
   "source": [
    "- Spark is built on the concept of distributed datasets, which contain arbitrary Java or Python objects. \n",
    "- You create a dataset from external data, then apply parallel operations to it. \n",
    "- The building block of the Spark API is its RDD API. \n",
    "- In the RDD API, there are two types of operations: transformations(which define a new dataset based on previous ones), and actions, which kick off a job to execute on a cluster. \n",
    "- On top of Sparkâ€™s RDD API, high level APIs are provided, e.g. DataFrame API and Machine Learning API. \n",
    "- These high level APIs provide a concise way to conduct certain data operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wrong-devices",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-S04CMFP:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark-Tutorial</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x236814eec10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark-Tutorial\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "joint-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|Gender|          Height|          Weight|\n",
      "+------+----------------+----------------+\n",
      "|  Male| 73.847017017515|241.893563180437|\n",
      "|  Male|68.7819040458903|  162.3104725213|\n",
      "|  Male|74.1101053917849|  212.7408555565|\n",
      "|  Male|71.7309784033377|220.042470303077|\n",
      "+------+----------------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"weight-height.csv\",header=True,inferSchema=True)\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "gentle-middle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "revolutionary-identification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"Gender\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-german",
   "metadata": {},
   "source": [
    "#### Encoding\n",
    "\n",
    "#to work on the features, spark MLlib expects every value to be in numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "operational-intake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|Gender|          Height|          Weight|\n",
      "+------+----------------+----------------+\n",
      "|     1| 73.847017017515|241.893563180437|\n",
      "|     1|68.7819040458903|  162.3104725213|\n",
      "|     1|74.1101053917849|  212.7408555565|\n",
      "|     1|71.7309784033377|220.042470303077|\n",
      "+------+----------------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Functions to replace values in column:\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df = df.withColumn('Gender', regexp_replace('Gender', 'Male', \"1\"))\n",
    "df = df.withColumn('Gender',regexp_replace('Gender', 'Female', \"2\"))\n",
    "\n",
    "#Using Cast to convert column type\n",
    "df = df.withColumn(\"Gender\",df.Gender.cast(\"int\"))\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-drive",
   "metadata": {},
   "source": [
    "#### Another Way to encode:\n",
    "\n",
    "Using StringIndexer, string type will be typecast to numeric datatype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ignored-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer\n",
    "# indexer =StringIndexer(inputCol='Gender',outputCol='Gender_n')\n",
    "# indexed= indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "broad-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: integer (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-portsmouth",
   "metadata": {},
   "source": [
    "Successfully converted to Int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-light",
   "metadata": {},
   "source": [
    "#### Defining Features for ML Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-marine",
   "metadata": {},
   "source": [
    "Treating Group of Features as an Indepedent feature. My group is [\"Gender\",\"Height\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "addressed-silence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+--------------------+\n",
      "|Gender|          Height|          Weight| independent feature|\n",
      "+------+----------------+----------------+--------------------+\n",
      "|     1| 73.847017017515|241.893563180437|[1.0,73.847017017...|\n",
      "|     1|68.7819040458903|  162.3104725213|[1.0,68.781904045...|\n",
      "|     1|74.1101053917849|  212.7408555565|[1.0,74.110105391...|\n",
      "|     1|71.7309784033377|220.042470303077|[1.0,71.730978403...|\n",
      "+------+----------------+----------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_assembler = VectorAssembler(inputCols=[\"Gender\",\"Height\"],outputCol=\"independent feature\")\n",
    "\n",
    "output = feature_assembler.transform(df)\n",
    "\n",
    "output.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "silver-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender', 'Height', 'Weight', 'independent feature']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-cannon",
   "metadata": {},
   "source": [
    "#### Columns to use: independent feature(X) and Weight(Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "coordinate-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "| independent feature|          Weight|\n",
      "+--------------------+----------------+\n",
      "|[1.0,73.847017017...|241.893563180437|\n",
      "|[1.0,68.781904045...|  162.3104725213|\n",
      "+--------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = output.select([\"independent feature\",\"Weight\"])\n",
    "data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-wages",
   "metadata": {},
   "source": [
    "#### Train-test Split: Using Random Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "accepted-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test =data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-surprise",
   "metadata": {},
   "source": [
    "#### Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "flush-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "regressor = LinearRegression(featuresCol=\"independent feature\",labelCol=\"Weight\").fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-orchestra",
   "metadata": {},
   "source": [
    "#### Coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "unnecessary-option",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-19.3176, 5.9941])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-charles",
   "metadata": {},
   "source": [
    "#### Intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "sharing-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-207.4142980684588"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-triumph",
   "metadata": {},
   "source": [
    "#### Calculating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "split-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+------------------+\n",
      "| independent feature|          Weight|        prediction|\n",
      "+--------------------+----------------+------------------+\n",
      "|[1.0,60.243718102...|153.831429216947| 134.3731069530535|\n",
      "|[1.0,60.935739701...|140.151715704819|138.52113162353376|\n",
      "|[1.0,61.074487103...|122.680111752611|139.35279301993788|\n",
      "|[1.0,61.226828660...|153.520978630761|140.26593870524735|\n",
      "+--------------------+----------------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = regressor.evaluate(test)\n",
    "prediction.predictions.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-banana",
   "metadata": {},
   "source": [
    "#### MAE , MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hazardous-native",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.301929134584867, 108.05439782844422)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.meanAbsoluteError , prediction.meanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-hacker",
   "metadata": {},
   "source": [
    "#### R-Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bridal-norwegian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8988267510829301"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-cassette",
   "metadata": {},
   "source": [
    "##### That is our model is around 90% Accurate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-tolerance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
