{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "august-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educational-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hungarian-porter",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>73.847017</td>\n",
       "      <td>241.893563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>68.781904</td>\n",
       "      <td>162.310473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>74.110105</td>\n",
       "      <td>212.740856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>71.730978</td>\n",
       "      <td>220.042470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>69.881796</td>\n",
       "      <td>206.349801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Female</td>\n",
       "      <td>66.172652</td>\n",
       "      <td>136.777454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Female</td>\n",
       "      <td>67.067155</td>\n",
       "      <td>170.867906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Female</td>\n",
       "      <td>63.867992</td>\n",
       "      <td>128.475319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Female</td>\n",
       "      <td>69.034243</td>\n",
       "      <td>163.852461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.944246</td>\n",
       "      <td>113.649103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender     Height      Weight\n",
       "0       Male  73.847017  241.893563\n",
       "1       Male  68.781904  162.310473\n",
       "2       Male  74.110105  212.740856\n",
       "3       Male  71.730978  220.042470\n",
       "4       Male  69.881796  206.349801\n",
       "...      ...        ...         ...\n",
       "9995  Female  66.172652  136.777454\n",
       "9996  Female  67.067155  170.867906\n",
       "9997  Female  63.867992  128.475319\n",
       "9998  Female  69.034243  163.852461\n",
       "9999  Female  61.944246  113.649103\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Dataset:\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"weight-height.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "absolute-retention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Gender  10000 non-null  object \n",
      " 1   Height  10000 non-null  float64\n",
      " 2   Weight  10000 non-null  float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()     #Its a Pandas DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-evolution",
   "metadata": {},
   "source": [
    "#### Starting a Pyspark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "remarkable-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Defing Object and Giving spark session a name\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark-Tutorial\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "armed-miracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-S04CMFP.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark-Tutorial</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x24222018610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-hours",
   "metadata": {},
   "source": [
    "#### Reading Dataset in Pyspark `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hundred-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(\"weight-height.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ready-tender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark       #3 columns in my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coupled-demonstration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|   _c0|             _c1|             _c2|\n",
      "+------+----------------+----------------+\n",
      "|Gender|          Height|          Weight|\n",
      "|  Male| 73.847017017515|241.893563180437|\n",
      "|  Male|68.7819040458903|162.310472521300|\n",
      "|  Male|74.1101053917849|  212.7408555565|\n",
      "|  Male|71.7309784033377|220.042470303077|\n",
      "+------+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "homeless-honor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|Gender|          Height|          Weight|\n",
      "+------+----------------+----------------+\n",
      "|  Male| 73.847017017515|241.893563180437|\n",
      "|  Male|68.7819040458903|162.310472521300|\n",
      "|  Male|74.1101053917849|  212.7408555565|\n",
      "|  Male|71.7309784033377|220.042470303077|\n",
      "|  Male|69.8817958611153|206.349800623871|\n",
      "+------+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Defining Columns Name:\n",
    "spark.read.csv(\"weight-height.csv\",header=True).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "american-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(\"weight-height.csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-spiritual",
   "metadata": {},
   "source": [
    "##### type of dataset changed from Pandas DF to PYSPARK SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-foundation",
   "metadata": {},
   "source": [
    "#### Pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "diverse-explanation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nasty-laser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Gender='Male', Height='73.847017017515', Weight='241.893563180437'),\n",
       " Row(Gender='Male', Height='68.7819040458903', Weight='162.310472521300'),\n",
       " Row(Gender='Male', Height='74.1101053917849', Weight='212.7408555565'),\n",
       " Row(Gender='Male', Height='71.7309784033377', Weight='220.042470303077')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-importance",
   "metadata": {},
   "source": [
    "#### PrintSchema Works like .info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "going-optimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Height: string (nullable = true)\n",
      " |-- Weight: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-vulnerability",
   "metadata": {},
   "source": [
    "#### Though Weight and Height are Float, Pyspark has by default taken them to be String!\n",
    "\n",
    "Pyspark considers all the columns as string until we provide : inferSchema=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "statistical-violence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"weight-height.csv\",header=True,inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "labeled-internship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender', 'Height', 'Weight']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns Name:\n",
    "\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "regional-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'Gender'>\n",
      "DataFrame[Gender: string]\n"
     ]
    }
   ],
   "source": [
    "#Selecting Individual Column:\n",
    "\n",
    "print(df_pyspark[\"Gender\"])   #As a Column \n",
    "\n",
    "print(df_pyspark.select(\"Gender\"))    #As a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ancient-indonesian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Gender: string, Weight: double]\n",
      "DataFrame[Gender: string, Weight: double]\n"
     ]
    }
   ],
   "source": [
    "#Selecting Multiple Column:\n",
    "\n",
    "print(df_pyspark[\"Gender\",\"Weight\"])   #As a Pyspark Dataframe\n",
    "\n",
    "print(df_pyspark.select(\"Gender\",\"Weight\"))    #As a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-excerpt",
   "metadata": {},
   "source": [
    "##### Show Applicable to Pyspark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broadband-dimension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|Gender|          Weight|\n",
      "+------+----------------+\n",
      "|  Male|241.893563180437|\n",
      "|  Male|  162.3104725213|\n",
      "|  Male|  212.7408555565|\n",
      "+------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark[\"Gender\",\"Weight\"].show(3)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bibliographic-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pyspark[\"Gender\"].show(3)  #Output is a column hence error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-assembly",
   "metadata": {},
   "source": [
    "#### Checking Datatypes in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "diverse-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gender', 'string'), ('Height', 'double'), ('Weight', 'double')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "floating-briefs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+------------------+\n",
      "|summary|Gender|           Height|            Weight|\n",
      "+-------+------+-----------------+------------------+\n",
      "|  count| 10000|            10000|             10000|\n",
      "|   mean|  null|66.36755975482106|161.44035683283076|\n",
      "| stddev|  null|3.847528120773333|32.108439006519674|\n",
      "|    min|Female| 54.2631333250971|   64.700126712753|\n",
      "|    max|  Male| 78.9987423463896|  269.989698505106|\n",
      "+-------+------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-exhibition",
   "metadata": {},
   "source": [
    "#### Adding Columns using With Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alone-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= df_pyspark.withColumn(\"Weight After 2 Years\",df_pyspark[\"Weight\"]+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "vocational-arrival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+------------------+--------------------+\n",
      "|summary|Gender|           Height|            Weight|Weight After 2 Years|\n",
      "+-------+------+-----------------+------------------+--------------------+\n",
      "|  count| 10000|            10000|             10000|               10000|\n",
      "|   mean|  null|66.36755975482106|161.44035683283076|   166.4403568328308|\n",
      "| stddev|  null|3.847528120773333|32.108439006519674|  32.108439006519674|\n",
      "|    min|Female| 54.2631333250971|   64.700126712753|     69.700126712753|\n",
      "|    max|  Male| 78.9987423463896|  269.989698505106|    274.989698505106|\n",
      "+-------+------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-tokyo",
   "metadata": {},
   "source": [
    "#### Dropping Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "existing-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= df_pyspark.drop(\"Weight After 2 Years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "christian-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|Gender|          Height|          Weight|\n",
      "+------+----------------+----------------+\n",
      "|  Male| 73.847017017515|241.893563180437|\n",
      "|  Male|68.7819040458903|  162.3104725213|\n",
      "|  Male|74.1101053917849|  212.7408555565|\n",
      "+------+----------------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-canyon",
   "metadata": {},
   "source": [
    "#### Renaming Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "applicable-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+\n",
      "| Sex|          Height|          Weight|\n",
      "+----+----------------+----------------+\n",
      "|Male| 73.847017017515|241.893563180437|\n",
      "|Male|68.7819040458903|  162.3104725213|\n",
      "+----+----------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = df_pyspark.withColumnRenamed(\"Gender\",\"Sex\")\n",
    "df_pyspark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-messenger",
   "metadata": {},
   "source": [
    "#### Dealing with Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "coupled-venture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Sex: string, Height: double, Weight: double]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.na.drop()           #Dropping all null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "discrete-worship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Sex: string, Height: double, Weight: double]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using ANY and ALL in HOW\n",
    "df_pyspark.na.drop(how=\"all\")         #Delete only those rows which have all values null \n",
    "\n",
    "df_pyspark.na.drop(how=\"any\")         #Delete  rows which have even 1 value as null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Threshold\n",
    "\n",
    "df_pyspark.na.drop(how=\"any\",thresh=2)     #At-least 2 non-null values should be present, if less than 2 values delete row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Subset\n",
    "\n",
    "df_pyspark.na.drop(how=\"any\",subset=[\"Weight\"])    #Delete all those rows in which Weight Values are Null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling Missing Values\n",
    "\n",
    "df_pyspark.na.fill(\"NA\")\n",
    "\n",
    "df_pyspark.na.fill(\"NA\",\"Weight\")    #Filling Missing values in Weight column with NA\n",
    "\n",
    "df_pyspark.na.fill(\"NA\",\"Weight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-pledge",
   "metadata": {},
   "source": [
    "#### Using Imputer to Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "angry-farming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+----------------+----------------+\n",
      "| Sex|          Height|          Weight|  Weight imputed|  Height imputed|\n",
      "+----+----------------+----------------+----------------+----------------+\n",
      "|Male| 73.847017017515|241.893563180437|241.893563180437| 73.847017017515|\n",
      "|Male|68.7819040458903|  162.3104725213|  162.3104725213|68.7819040458903|\n",
      "|Male|74.1101053917849|  212.7408555565|  212.7408555565|74.1101053917849|\n",
      "|Male|71.7309784033377|220.042470303077|220.042470303077|71.7309784033377|\n",
      "+----+----------------+----------------+----------------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=[\"Weight\",\"Height\"],\n",
    "                  outputCols=[\"{} imputed\".format(c) for c in [\"Weight\",\"Height\"]]).setStrategy(\"mean\")\n",
    "\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show(4)                 #Replaced the missing values with mean\n",
    "\n",
    "#Can be similarly done for median , mode etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-estonia",
   "metadata": {},
   "source": [
    "#### Filter Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "employed-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5797"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weight less than 170\n",
    "print(df_pyspark.count())\n",
    "df_pyspark.filter(\"Weight<=170\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategic-certification",
   "metadata": {},
   "source": [
    "- row_number = data.count()\n",
    "- column_number = len(data.dtypes)\n",
    "- Shape : print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "public-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_pyspark.columns))\n",
    "\n",
    "df_pyspark.count(),len(df_pyspark.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-yukon",
   "metadata": {},
   "source": [
    "### Filtering and Selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "technical-horizontal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|          Weight|          Height|\n",
      "+----------------+----------------+\n",
      "|  162.3104725213|68.7819040458903|\n",
      "|152.212155757083|67.2530156878065|\n",
      "|167.971110489509|68.3485155115879|\n",
      "|156.399676387112|63.4564939783664|\n",
      "|167.127461073476|64.7663291334055|\n",
      "|149.173566007975|66.1491319608781|\n",
      "+----------------+----------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Weight<=170\").select([\"Weight\",\"Height\"]).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-vegetarian",
   "metadata": {},
   "source": [
    "#### AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "prompt-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+\n",
      "|          Weight|         Height|\n",
      "+----------------+---------------+\n",
      "|241.893563180437|73.847017017515|\n",
      "+----------------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Weight<=170\" and \"Height>70\").select([\"Weight\",\"Height\"]).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "sustainable-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|          Weight|          Height|\n",
      "+----------------+----------------+\n",
      "|167.301408606857|70.0941169135012|\n",
      "+----------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark[\"Weight\"]<=170) & (df_pyspark[\"Height\"]>70)).select([\"Weight\",\"Height\"]).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-crystal",
   "metadata": {},
   "source": [
    "#### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "soviet-rebel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|          Weight|          Height|\n",
      "+----------------+----------------+\n",
      "|  162.3104725213|68.7819040458903|\n",
      "|152.212155757083|67.2530156878065|\n",
      "|167.971110489509|68.3485155115879|\n",
      "|156.399676387112|63.4564939783664|\n",
      "|167.127461073476|64.7663291334055|\n",
      "|149.173566007975|66.1491319608781|\n",
      "+----------------+----------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Weight<=170\" or \"Height>70\").select([\"Weight\",\"Height\"]).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-iraqi",
   "metadata": {},
   "source": [
    "#### NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "productive-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|          Weight|          Height|\n",
      "+----------------+----------------+\n",
      "|241.893563180437| 73.847017017515|\n",
      "|  212.7408555565|74.1101053917849|\n",
      "|220.042470303077|71.7309784033377|\n",
      "|206.349800623871|69.8817958611153|\n",
      "|183.927888604031|68.7850812516616|\n",
      "| 175.92944039571| 67.018949662883|\n",
      "+----------------+----------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark[\"Weight\"]<=170)).select([\"Weight\",\"Height\"]).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-plain",
   "metadata": {},
   "source": [
    "#### PySpark GroupBy and Aggregate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "comprehensive-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-----------------+\n",
      "|   Sex|       sum(Height)|      sum(Weight)|\n",
      "+------+------------------+-----------------+\n",
      "|Female| 318543.8680171246|679300.4650373434|\n",
      "|  Male|345131.72953108686|935103.1032909645|\n",
      "+------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupby sum\n",
    "\n",
    "df_pyspark.groupby(\"Sex\").sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "given-newark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|   Sex|count|\n",
      "+------+-----+\n",
      "|Female| 5000|\n",
      "|  Male| 5000|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupby count \n",
    "df_pyspark.groupby(\"Sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "southwest-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|   Sex|     max(Height)|     max(Weight)|\n",
      "+------+----------------+----------------+\n",
      "|Female|73.3895858660697|202.237213739559|\n",
      "|  Male|78.9987423463896|269.989698505106|\n",
      "+------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupby Max\n",
    "df_pyspark.groupby(\"Sex\").max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "moving-victim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+----------------+\n",
      "|   Sex|     min(Height)|     min(Weight)|\n",
      "+------+----------------+----------------+\n",
      "|Female|54.2631333250971| 64.700126712753|\n",
      "|  Male|58.4069049317498|112.902939447818|\n",
      "+------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupby Min\n",
    "df_pyspark.groupby(\"Sex\").min().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "incorporate-bumper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-----------------+\n",
      "|   Sex|       avg(Height)|      avg(Weight)|\n",
      "+------+------------------+-----------------+\n",
      "|Female|63.708773603424916|135.8600930074687|\n",
      "|  Male| 69.02634590621737|187.0206206581929|\n",
      "+------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupby Avg\n",
    "df_pyspark.groupby(\"Sex\").avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "rational-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-----------------+\n",
      "|   Sex|       avg(Height)|      avg(Weight)|\n",
      "+------+------------------+-----------------+\n",
      "|Female|63.708773603424916|135.8600930074687|\n",
      "|  Male| 69.02634590621737|187.0206206581929|\n",
      "+------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Groupby mean\n",
    "df_pyspark.groupby(\"Sex\").mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "champion-woman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sum(Height)=663675.5975482106)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aggregate\n",
    "\n",
    "#Overall sum of Height\n",
    "df_pyspark.agg({\"Height\":\"sum\"}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "continent-alarm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|     max(Height)|\n",
      "+----------------+\n",
      "|78.9987423463896|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({\"Height\":\"max\"}).show()    #Directly applying aggregate functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-sight",
   "metadata": {},
   "source": [
    "##### Types of Aggregate functions: Sum, Count, Avg etc : Applied after grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "multiple-degree",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|   Sex|     max(Height)|\n",
      "+------+----------------+\n",
      "|Female|73.3895858660697|\n",
      "|  Male|78.9987423463896|\n",
      "+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupby(\"Sex\").agg({\"Height\":\"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-globe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
